# Combining-Petsc-and-Slepc-with-MPI

This is an optimized version of the code that has been provided in the respository "Polaron Coherence in 2D aggregates." I have used Petsc and Slepc along with MPI. The new optimized code runs almost 20 times faster and requires a lot less memory.

What is included?
-----------------

I have included the full code along with the makefile. There are some additional subroutines which deals with P3HT stacks doped with F4TCNQ anions.

Petsc and Slepc
---------------
In order to understand this code, you need to know the basics of Petsc and Slepc. There are a lot of tutorials in the internet where you can learn about Petsc and Slepc. 

Here are some links:

Slepc : http://slepc.upv.es/documentation/

Petsc : https://www.mcs.anl.gov/petsc/documentation/tutorials/HandsOnExercise.html

There are a lot of good pdfs available on the internet which will explain how to use petsc and slepc for C++, python and Fortran. 







